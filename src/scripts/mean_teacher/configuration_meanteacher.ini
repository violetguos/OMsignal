[data]
normalize = False
fft = False

[optimizer]
learning_rate = 0.00001
initial_lr = 5E-6
lr_rampup = 40
lr_rampdown = 250
nepoch = 100
weight_decay = 1E-4

[dataloader]
batch_size = 128
labeled_batch_size = 32
augment = True

[model]
name = CONV1D
hidden_size = 24
dropout = 0.5
n_layers = 1
kernel_size = 6
pool_size = 4
dilation = 4

[meanteacher]
EMA_decay = 0.99
consistency = True
consistency_rampup = 30
consistency_type = mse
checkpoint_epochs = 5
evaluation_epochs = 1

[path]
model = Models/baseline_final
tensorboard = Tensorboard/mean_teacher
